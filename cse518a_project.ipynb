{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gridworld import GridworldMdp\n",
    "from agents import OptimalAgent\n",
    "from mdp_interface import Mdp\n",
    "from agent_runner import get_reward_from_trajectory\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Intervention:\n",
    "\n",
    "    def __init__(self,trial_length=10,num_interventions=3,gamma=0.9):\n",
    "        self.steps_left = trial_length\n",
    "        self.interventions_left = num_interventions\n",
    "        self.optimal_agent = OptimalAgent(gamma=gamma)\n",
    "\n",
    "    def set_mdp(self,mdp):\n",
    "        self.optimal_agent.set_mdp(mdp)\n",
    "\n",
    "    def get_optimal_action(self,state):\n",
    "        return self.optimal_agent.get_action(state)\n",
    "\n",
    "    def will_intervene(self,state,agent_action):\n",
    "        raise NotImplemented(\"Cannot call will_intervene for Intervention\")\n",
    "\n",
    "    def get_action(self,state,agent_action):\n",
    "        if self.will_intervene(state,agent_action):\n",
    "            self.interventions_left -= 1\n",
    "            self.steps_left -= 1\n",
    "            return self.get_optimal_action(state)\n",
    "        self.steps_left -= 1\n",
    "        return agent_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomIntervention(Intervention):\n",
    "\n",
    "    def will_intervene(self, state, agent_action):\n",
    "        prob = self.interventions_left / self.steps_left\n",
    "        return np.random.rand() < prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 8\n",
    "width = 8\n",
    "num_rewards = 4\n",
    "noise = 0\n",
    "gamma = 0.9\n",
    "trial_length = 10\n",
    "num_interventions = 3\n",
    "num_trials = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trial(agent, intervention):\n",
    "\n",
    "    mdp = GridworldMdp.generate_random_connected(height,width,num_rewards,noise)\n",
    "    env = Mdp(mdp)\n",
    "    agent.set_mdp(mdp)\n",
    "    intervention.set_mdp(mdp)\n",
    "    trajectory = []\n",
    "\n",
    "    for _ in range(trial_length):\n",
    "        curr_state = env.get_current_state()\n",
    "        agent_action = agent.get_action(curr_state)\n",
    "        action = intervention.get_action(curr_state,agent_action)\n",
    "        next_state, reward = env.perform_action(action)\n",
    "        minibatch = (curr_state, action, next_state, reward)\n",
    "        agent.inform_minibatch(*minibatch)\n",
    "        trajectory.append(minibatch)\n",
    "\n",
    "    reward = get_reward_from_trajectory(trajectory,gamma)\n",
    "    return reward\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 12.262472396000001, 30.398624792000007, 5.436020897000002, 34.20184039100001, 27.633550391000007, 17.695858192999996, 0.0, 1.9492364960000008, 5.132568086000002, 18.410903593999997, 22.792193594, 6.486148313000001, 14.517993293, 3.836383487000002, 20.166358192999994, 14.467742594, 12.049626995, 13.182546797000002, 5.062472396000001, 32.27350919300001, 18.433862396, 7.213395797000002, 0.0, 18.410903593999997, 30.398624792000007, 26.595409193000002, 30.398624792000007, 22.136903594, 0.0, 0.0, 7.263646496000002, 34.20184039100001, 9.714148891999999, 11.120646797000001, 30.398624792000007, 0.0, 41.49994039100001, 24.559334792, 41.49994039100001, 18.433862396, 23.133550391000007, 27.633550391000007, 47.799940391000014, 16.679573792, 14.467742594, 44.095724792000006, 14.199397694000004, 8.833395797000001, 22.939334792]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _ in range(num_trials):\n",
    "    agent = OptimalAgent(gamma=gamma)\n",
    "    intervention = RandomIntervention(num_interventions=num_interventions,gamma=gamma)\n",
    "    reward = run_trial(agent,intervention)\n",
    "    results.append(reward)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed64e5a8ec65e8575703d495269facee7e989d76102892ef4c34bce8b4483af7"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('gridworld': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
